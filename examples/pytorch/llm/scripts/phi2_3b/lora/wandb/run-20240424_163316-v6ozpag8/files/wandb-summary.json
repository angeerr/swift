{"loss": 0.8247694, "grad_norm": 14.5625, "learning_rate": 9.230769230769231e-07, "rewards/chosen": 0.36398419737815857, "rewards/rejected": 0.316335529088974, "rewards/accuracies": 0.6000000238418579, "rewards/margins": 0.04764864966273308, "logps/rejected": -107.4061279296875, "logps/chosen": -82.58366394042969, "logps/ref_rejected": -110.56949615478516, "logps/ref_chosen": -86.2235107421875, "logits/rejected": 0.1302390992641449, "logits/chosen": 0.04817821457982063, "epoch": 0.56, "_timestamp": 1713960967.2202303, "_runtime": 13370.352122306824, "_step": 306, "eval_loss": 0.8066374063491821, "eval_runtime": 107.7151, "eval_samples_per_second": 3.862, "eval_steps_per_second": 0.241, "eval_rewards/chosen": 0.40665656328201294, "eval_rewards/rejected": 0.312563955783844, "eval_rewards/accuracies": 0.6177884340286255, "eval_rewards/margins": 0.09409257769584656, "eval_logps/rejected": -106.18977355957031, "eval_logps/chosen": -82.14350891113281, "eval_logps/ref_rejected": -109.31541442871094, "eval_logps/ref_chosen": -86.21006774902344, "eval_logits/rejected": 0.07036826014518738, "eval_logits/chosen": -0.0008911536424420774}