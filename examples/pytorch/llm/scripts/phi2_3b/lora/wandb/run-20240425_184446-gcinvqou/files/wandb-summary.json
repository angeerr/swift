{"train_loss": 0.21661215505482237, "logits/chosen": 0.023467320948839188, "logps/rejected": -111.31181335449219, "rewards/margins": 0.08939732611179352, "logps/ref_chosen": -75.75608825683594, "eval_rewards/chosen": 0.2032923400402069, "eval_logps/ref_chosen": -86.21006774902344, "eval_loss": 0.8209664225578308, "logps/chosen": -73.4698486328125, "learning_rate": 1.94331983805668e-06, "eval_logps/chosen": -84.17715454101562, "eval_logits/rejected": 0.05169053375720978, "eval_rewards/rejected": 0.13395264744758606, "eval_samples_per_second": 3.866, "_timestamp": 1714045856.2621398, "_runtime": 27338.40657567978, "eval_logits/chosen": -0.01729757897555828, "logits/rejected": 0.1076892614364624, "rewards/rejected": 0.13922585546970367, "train_samples_per_second": 7.131, "_step": 109, "eval_runtime": 107.6008, "train_runtime": 5833.3289, "logps/ref_rejected": -112.7040786743164, "eval_logps/ref_rejected": -109.31541442871094, "eval_rewards/accuracies": 0.651442289352417, "grad_norm": 17.0, "total_flos": 0, "rewards/chosen": 0.2286231517791748, "eval_logps/rejected": -107.97588348388672, "eval_rewards/margins": 0.06933968514204025, "eval_steps_per_second": 0.242, "loss": 0.79997039, "epoch": 0.12, "rewards/accuracies": 0.675000011920929, "train_steps_per_second": 0.028}